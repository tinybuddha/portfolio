{"cells":[{"cell_type":"markdown","id":"5a317524-e230-445d-90da-c2cf17699a12","metadata":{"id":"5a317524-e230-445d-90da-c2cf17699a12","tags":[]},"source":["# Hate speech detection task\n","\n","Hate speech detection is the automated task of determining whether a piece of text contains hateful content. In this project, I built a classifier using PyTorch and a pre-trained BERT model.\n","\n","**Data source:** Hate Towards the Political Opponent: A Twitter Corpus Study of the 2020 US Elections on the Basis of Offensive Speech and Stance Detection https://www.ims.uni-stuttgart.de/forschung/ressourcen/korpora/stance-hof/"]},{"cell_type":"markdown","id":"9c5f3887-5ed7-4c42-bc33-57dcb51550fc","metadata":{"id":"9c5f3887-5ed7-4c42-bc33-57dcb51550fc"},"source":["## GPU set-up"]},{"cell_type":"code","execution_count":3,"id":"dd2107fc-38dd-46a1-9043-65350cc82d41","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2912,"status":"ok","timestamp":1667917932769,"user":{"displayName":"Matt Chapman","userId":"15238629434520334129"},"user_tz":0},"id":"dd2107fc-38dd-46a1-9043-65350cc82d41","outputId":"c7b7369b-77fa-47ce-f3b6-048c217203ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["No GPU available, using the CPU instead.\n"]}],"source":["import torch\n","   \n","# If there's a GPU available...\n","if torch.cuda.is_available():\n","\n","    # Tell PyTorch to use the GPU.\n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"]},{"cell_type":"markdown","id":"c7f1b9be-f2e1-407c-89b5-0ab50789090d","metadata":{"id":"c7f1b9be-f2e1-407c-89b5-0ab50789090d"},"source":["## Load libraries"]},{"cell_type":"code","execution_count":4,"id":"272f722d-1680-4e16-add8-5085bf7a50f1","metadata":{"id":"272f722d-1680-4e16-add8-5085bf7a50f1"},"outputs":[],"source":["import os\n","from pathlib import Path\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import re\n","from string import punctuation\n","from collections import Counter\n","import random\n","import operator\n","from tqdm import tqdm\n","import time\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","import torch\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","\n","from transformers import BertModel, BertTokenizer"]},{"cell_type":"markdown","id":"4ba6f892-fd29-4a1f-9a17-2efb6d2e2adf","metadata":{"id":"4ba6f892-fd29-4a1f-9a17-2efb6d2e2adf"},"source":["## Load data\n","\n","Note that I will only use two of the columns: 'text' and 'HOF' (i.e. the label). The other columns (sentiment towards Trump, Biden and West) are superfluous to the current (simple) task."]},{"cell_type":"code","execution_count":11,"id":"315f77d2-4d1e-402d-8bd2-8047fa9dbebd","metadata":{"id":"315f77d2-4d1e-402d-8bd2-8047fa9dbebd"},"outputs":[],"source":["def load_data(path, sample_size=5, cols=['text', 'HOF'], label=None):\n","    \"\"\"Helper function that loads data from a given path into a pandas\n","       DataFrame, using only the specified cols. Also prints basic info\n","       about the dataset size and displays a sample of the rows.\n","    \"\"\"\n","    \n","    df = pd.read_csv(\"/home/niki/Code/Notebooks/data/train.tsv\", sep='\\t', usecols=cols)\n","    df = pd.read_csv(\"/home/niki/Code/Notebooks/data/test.tsv\", sep='\\t', usecols=cols)\n","\n","    print(f\"\\nThere are {df.shape[0]} tweets in the {label} dataset.\")\n","    print(\"\\nHere's a sample:\\n\")\n","    display(df.sample(sample_size))\n","\n","    return df"]},{"cell_type":"code","execution_count":12,"id":"FMvZ-Qzb1gBq","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"executionInfo":{"elapsed":2069,"status":"error","timestamp":1667917982943,"user":{"displayName":"Matt Chapman","userId":"15238629434520334129"},"user_tz":0},"id":"FMvZ-Qzb1gBq","outputId":"07379460-36ac-4ecc-8eaf-9f3fc74fa3bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","There are 600 tweets in the train dataset.\n","\n","Here's a sample:\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>HOF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>205</th>\n","      <td>Charlamagne tha God says he's voting for 'chan...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>@MSNBC @NGirrard Why did Senators and Congress...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>577</th>\n","      <td>@HKrassenstein Not a trump supporter in site. ...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>@dancer39532 @realDonaldTrump Joe Biden’s a ra...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>@RickSaccone4PA This is going to send a surge ...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  text          HOF\n","205  Charlamagne tha God says he's voting for 'chan...  Non-Hateful\n","151  @MSNBC @NGirrard Why did Senators and Congress...  Non-Hateful\n","577  @HKrassenstein Not a trump supporter in site. ...  Non-Hateful\n","6    @dancer39532 @realDonaldTrump Joe Biden’s a ra...  Non-Hateful\n","66   @RickSaccone4PA This is going to send a surge ...  Non-Hateful"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","There are 600 tweets in the test dataset.\n","\n","Here's a sample:\n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>HOF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49</th>\n","      <td>DoJ labels New York, Portland and Seattle 'ana...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>@leftcoastlefty5 @FunnestBestest Pence is the ...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>238</th>\n","      <td>@TrumpWarRoom Speaking truth. Everyone should ...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>532</th>\n","      <td>@bertkreischer Carson on #Biden2020 https://t....</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>So quick question: is there a term limit on be...</td>\n","      <td>Non-Hateful</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  text          HOF\n","49   DoJ labels New York, Portland and Seattle 'ana...  Non-Hateful\n","48   @leftcoastlefty5 @FunnestBestest Pence is the ...  Non-Hateful\n","238  @TrumpWarRoom Speaking truth. Everyone should ...  Non-Hateful\n","532  @bertkreischer Carson on #Biden2020 https://t....  Non-Hateful\n","12   So quick question: is there a term limit on be...  Non-Hateful"]},"metadata":{},"output_type":"display_data"}],"source":["# Colab\n","train = load_data('train.tsv', label='train')\n","test = load_data('test.tsv', label='test')"]},{"cell_type":"code","execution_count":13,"id":"82c728a5-f3f6-4358-a7f7-1e4a10e95f02","metadata":{"id":"82c728a5-f3f6-4358-a7f7-1e4a10e95f02"},"outputs":[],"source":["# Are there any duplicates?\n","assert len(train['text'].drop_duplicates()) == len(train['text'])\n","assert len(test['text'].drop_duplicates()) == len(test['text'])"]},{"cell_type":"markdown","id":"d0015082-f682-4258-95f7-09317050a424","metadata":{"id":"d0015082-f682-4258-95f7-09317050a424"},"source":["## Quick inspection / visualisation"]},{"cell_type":"code","execution_count":14,"id":"873a9381-da14-47f0-8bda-729af7e96705","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"873a9381-da14-47f0-8bda-729af7e96705","outputId":"afec320b-e8be-4ce6-fede-19294815554d"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 720x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n","\n","# Distribution by class\n","ax[0].bar(x = train['HOF'].unique(), # Data labels\n","       height = train['HOF'].value_counts().values, # Num of tweets in each category\n","       color='purple')\n","\n","ax[0].bar_label(ax[0].containers[0], label_type='edge', padding=3) # Annotate bars\n","ax[0].set_ylim(0, 2300) # Raise upper limit of y-axis, to accommodate labels\n","\n","ax[0].set_title(\"Number of hateful/non-hateful tweets in the train dataset\",\n","             fontweight='bold', fontsize=10, y = 1.02)\n","ax[0].set_ylabel(\"Number of tweets\")\n","ax[0].set_xlabel('Tweet label')\n","\n","# Distribution by length\n","ax[1].hist([len(tweet) for tweet in train['text'].apply(lambda x: x.split())],\n","           color='orange', rwidth=0.8)\n","ax[1].set_xlabel('Token count')\n","ax[1].set_ylabel('Number of tweets')\n","ax[1].set_title(\"Histogram of tweet length\",\n","                fontweight='bold', fontsize=10, y = 1.02)\n","\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","id":"00ac50bc-50b4-4618-813e-251c736e1e53","metadata":{"id":"00ac50bc-50b4-4618-813e-251c736e1e53"},"source":["## Preprocess data\n","At this stage, I will just map the labels to integers. Later, I will conduct more preprocessing."]},{"cell_type":"code","execution_count":15,"id":"066df694-72b8-413e-88d1-c264b33f8488","metadata":{"id":"066df694-72b8-413e-88d1-c264b33f8488"},"outputs":[],"source":["# Map labels to binary integers\n","label2id = {'Non-Hateful': 0, 'Hateful': 1}\n","train['HOF'] = train['HOF'].apply(lambda x: label2id[x])\n","test['HOF'] = test['HOF'].apply(lambda x: label2id[x])"]},{"cell_type":"markdown","id":"d9879452-c9a7-4920-9593-80d9c6c0c88c","metadata":{"id":"d9879452-c9a7-4920-9593-80d9c6c0c88c"},"source":["## Deal with class imbalances\n","For simplicity / for now, I'll just downsample from the majority ('Non-Hateful') class."]},{"cell_type":"code","execution_count":16,"id":"1087ed2d-0e52-47ef-b505-aa20a93e7128","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1654585546640,"user":{"displayName":"Matt Chapman","userId":"15238629434520334129"},"user_tz":-60},"id":"1087ed2d-0e52-47ef-b505-aa20a93e7128","outputId":"d05b9fc2-2e1c-4aaa-831b-588df4b064bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Before downsampling: \n","Hateful: 59\n","Non-Hateful: 541\n","\n","After downsampling: \n","Hateful: 59\n","Non-Hateful: 59\n"]}],"source":["print('Before downsampling: ')\n","print(f\"Hateful: {len(train[train['HOF']==1])}\")\n","print(f\"Non-Hateful: {len(train[train['HOF']==0])}\")\n","\n","train_hateful = train[train['HOF']==1]\n","train_nonhateful = train[train['HOF']==0].sample(len(train_hateful))\n","train_downsampled = pd.concat([train_hateful, train_nonhateful], axis=0).sample(frac=1)\n","\n","print('\\nAfter downsampling: ')\n","print(f\"Hateful: {len(train_downsampled[train_downsampled['HOF']==1])}\")\n","print(f\"Non-Hateful: {len(train_downsampled[train_downsampled['HOF']==0])}\")"]},{"cell_type":"markdown","id":"45c14cfc-644a-4ec0-a8cb-1125cd0ebd2d","metadata":{"id":"45c14cfc-644a-4ec0-a8cb-1125cd0ebd2d"},"source":["## Split train data set into train and development sets\n","To provide a way to assess the model's performance after each training loop."]},{"cell_type":"code","execution_count":17,"id":"4d200564-3749-4a4a-a791-0f7bacaecf31","metadata":{"id":"4d200564-3749-4a4a-a791-0f7bacaecf31"},"outputs":[],"source":["# Split train data set into train and development sets\n","train, dev = train_test_split(train_downsampled, test_size=0.5, stratify=train_downsampled['HOF'])"]},{"cell_type":"markdown","id":"dca382a5-9690-4b01-9d84-719637414aec","metadata":{"id":"dca382a5-9690-4b01-9d84-719637414aec"},"source":["## Prepare data\n","\n","Before we can build and train our model, we need to convert the text and labels into a format that is acceptable for the model. To do this, we need two tools:\n","* `torch.utils.data.Dataset` - stores the samples and their corresponding labels. I also use it to create a simple pipeline for cleaning and tokenizing the tweets. I will use the `bert-base-uncased` tokenizer so that the tokenizer matches the model. This is because (1) the model has a specific, fixed vocabulary, and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words.\n","* `torch.utils.data.DataLoader` - wraps an iterable around the `Dataset`, enabling us to iterate through the samples. Can also be used to transform the data (if you provide a custom `collate_fn`).\n"]},{"cell_type":"code","execution_count":18,"id":"4abbc280-c5ae-450d-9b38-b916b676d2f4","metadata":{"id":"4abbc280-c5ae-450d-9b38-b916b676d2f4"},"outputs":[],"source":["# Clean the tweets' text\n","def clean_text(tweet):\n","    \"\"\"A function that performs basic cleaning of a tweet's text.\n","    \"\"\"\n","\n","    # Replace mentions and URLs with special token\n","    tweet = re.sub(r\"@[A-Za-z0-9_-]+\",'USR',tweet)\n","    tweet = re.sub(r\"http\\S+\",'URL',tweet)\n","\n","    # Remove \\n and \\t characters\n","    tweet = tweet.replace('\\n', ' ')\n","    tweet = tweet.replace('[NEWLINE]', ' ')\n","    tweet = tweet.replace('\\t', ' ')\n","\n","    # Strip whitespace\n","    tweet = tweet.strip()\n","\n","    # Convert to lowercase\n","    tweet = tweet.lower()\n","\n","    # return [w.strip(punctuation) for w in tweet.split() if w.strip(punctuation)!='']\n","    return tweet\n","\n","# train['cleaned_text'] = train['text'].apply(lambda x: clean_text(x))\n","# test['cleaned_text'] = test['text'].apply(lambda x: clean_text(x))"]},{"cell_type":"code","execution_count":45,"id":"0888abca-b22f-4c39-9818-dd5d21da546f","metadata":{"id":"0888abca-b22f-4c39-9818-dd5d21da546f","tags":[]},"outputs":[],"source":["# Define Dataset class which cleans, tokenies and encodes data\n","class BERTDataset(Dataset):\n","\n","  def __init__(self, data):\n","\n","        # Initialize BERT tokenizer\n","        # Note that I need to specify cache_dir because I'm using a venv\n","        self.tok = BertTokenizer.from_pretrained('bert-base-uncased', cache_dir=Path.cwd()/'venv/lib/python3.8/site-packages')\n","\n","        # Clean tweets\n","        self.cleaned_tweets = data['text'].apply(lambda x: clean_text(x))\n","\n","        # Truncate and encode tweets, up to max_length of 60\n","        # While this is lower than BERT's max (512), it was chosen for computational speed\n","        self.tweets = list(self.cleaned_tweets.apply(self.tok.encode, max_length=60, truncation=True))\n","\n","        # Store labels\n","        self.labels = list(data['HOF'])\n","\n","def __len__(self):\n","        return len(self.labels)\n","\n","def __getitem__(self, idx):\n","        tweet = self.tweets[idx]\n","        label = self.labels[idx]\n","        return tweet, label\n","\n","# Inspect an example\n","# BD = BERTDataset(train.iloc[:5])\n","# next(iter(BD))"]},{"cell_type":"code","execution_count":20,"id":"57e6c0f5-b979-4caa-a028-efada141ee4f","metadata":{"id":"57e6c0f5-b979-4caa-a028-efada141ee4f"},"outputs":[],"source":["# Define collate function to be passed to DataLoader\n","def bert_collate(batch):\n","\n","    # Store batch size\n","    batch_size = len(batch)\n","\n","    # Separate tweets and labels\n","    tweets = [t for t, _ in batch]\n","    labels = torch.tensor([l for _, l in batch]).long()\n","\n","    # Store length of longest tweet in batch\n","    max_len = max(len(t) for t in tweets)\n","\n","    # Create padded tweet and attention mask tensors\n","    tweets_pad = torch.zeros((batch_size, max_len)).long()\n","    masks_pad = torch.zeros((batch_size, max_len)).long()\n","    for i, t in enumerate(tweets):\n","        tweets_pad[i, :len(t)] = torch.tensor(t)\n","        masks_pad[i, :len(t)] = 1\n","\n","    return tweets_pad, masks_pad, labels"]},{"cell_type":"code","execution_count":21,"id":"3be599e0-0659-455e-96ed-c11605c9449b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1761,"status":"ok","timestamp":1654585567897,"user":{"displayName":"Matt Chapman","userId":"15238629434520334129"},"user_tz":-60},"id":"3be599e0-0659-455e-96ed-c11605c9449b","outputId":"a0a20fa1-e681-4d3c-aaab-432e00b71049"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 2.04 s, sys: 101 ms, total: 2.14 s\n","Wall time: 2.48 s\n"]}],"source":["%%time\n","\n","# Create data sets\n","train_dataset = BERTDataset(train)\n","dev_dataset = BERTDataset(dev)\n","test_dataset = BERTDataset(test)"]},{"cell_type":"code","execution_count":22,"id":"e06f9d8d-92f3-4ea3-b8ea-cf7f6a149c4c","metadata":{"id":"e06f9d8d-92f3-4ea3-b8ea-cf7f6a149c4c"},"outputs":[],"source":["# Create data loaders using torch.utils.data.DataLoader class\n","# Using shuffle=True instead of specifying RandomSampler\n","train_loader = DataLoader(train_dataset, batch_size=100, collate_fn=bert_collate, shuffle=True)\n","dev_loader = DataLoader(dev_dataset, batch_size=100, collate_fn=bert_collate)\n","test_loader = DataLoader(test_dataset, batch_size=100, collate_fn=bert_collate)"]},{"cell_type":"code","execution_count":23,"id":"0183c520-d528-4012-859d-4b66e103f0ed","metadata":{"collapsed":true,"id":"0183c520-d528-4012-859d-4b66e103f0ed","jupyter":{"outputs_hidden":true,"source_hidden":true},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","--------------------- Batch 0 ---------------------\n","\n","There are 59 encoded tweets in this batch.\n","Tweets (encoded):  tensor([[ 101, 2149, 2099,  ...,    0,    0,    0],\n","        [ 101, 2149, 2099,  ...,    0,    0,    0],\n","        [ 101, 2074, 2178,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 2149, 2099,  ..., 1057, 2360,  102],\n","        [ 101, 3533, 7226,  ...,    0,    0,    0],\n","        [ 101, 2149, 2099,  ...,    0,    0,    0]])\n","There are 59 encoded labels in this batch. Here they are: \n","Labels:  tensor([1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n","        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n","        1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1])\n"]}],"source":["# Inspect\n","for (idx, batch) in enumerate(train_loader):\n","\n","    print(f'\\n\\n--------------------- Batch {idx} ---------------------\\n')\n","\n","    # Print the text\n","    print(f\"There are {len(batch[0])} encoded tweets in this batch.\")\n","    print('Tweets (encoded): ', batch[0])\n","\n","    # Print the label\n","    print(f\"There are {len(batch[2])} encoded labels in this batch. Here they are: \")\n","    print('Labels: ', batch[2])"]},{"cell_type":"code","execution_count":46,"id":"31a5d582-1871-4060-89e4-f9309672d486","metadata":{"id":"31a5d582-1871-4060-89e4-f9309672d486"},"outputs":[],"source":["# Define BERT classifier\n","class BERTClassifier(nn.Module):\n","\n","    def __init__(self):\n","\n","        # Specify network layers\n","        # Note that I need to specify cache as I'm using a venv\n","        super(BERTClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased', cache_dir=Path.cwd()/'venv/lib/python3.8/site-packages')\n","        self.linear = nn.Linear(768, 4)\n","\n","        # Define dropout\n","        self.dropout = nn.Dropout(0.2)\n","\n","        # Freeze BERT layers\n","        for n, p in self.bert.named_parameters():\n","            p.requires_grad = False\n","\n","    def forward(self, tweets, masks):\n","\n","        # Define flow of tensors through the network\n","        output_bert = self.bert(tweets, attention_mask=masks)[0].mean(axis=1)\n","        return self.linear(self.dropout(output_bert))"]},{"cell_type":"code","execution_count":25,"id":"b06d91fe-61c5-41e4-b898-df69453cd32e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1560,"status":"ok","timestamp":1654585581606,"user":{"displayName":"Matt Chapman","userId":"15238629434520334129"},"user_tz":-60},"id":"b06d91fe-61c5-41e4-b898-df69453cd32e","outputId":"0310a43e-5795-41a3-b0d6-5110c0f7b800"},"outputs":[{"name":"stderr","output_type":"stream","text":["model.safetensors: 100%|██████████| 440M/440M [00:24<00:00, 17.8MB/s] \n"]}],"source":["# Initialise model\n","model = BERTClassifier()"]},{"cell_type":"markdown","id":"407b8317-9e4c-4978-b7fb-c16c8fa840fa","metadata":{"id":"407b8317-9e4c-4978-b7fb-c16c8fa840fa"},"source":["The warning above: This only means that the pretrained head of the BERT model is discarded, and replaced with a randomly initialised classification head. It doesn't matter that this is randomly initialised because we will now fine-tune this new model head via training below."]},{"cell_type":"code","execution_count":26,"id":"87742036-3111-4fe1-a096-4e0be8e2fd03","metadata":{"id":"87742036-3111-4fe1-a096-4e0be8e2fd03"},"outputs":[],"source":["# Move model to device\n","model = model.to(device)"]},{"cell_type":"code","execution_count":27,"id":"5c1edb0b-dc7f-4bc4-ba17-9ef101dcd947","metadata":{"id":"5c1edb0b-dc7f-4bc4-ba17-9ef101dcd947"},"outputs":[],"source":["# Define optimiser, objective function and epochs\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","criterion = nn.CrossEntropyLoss()\n","epochs = 5"]},{"cell_type":"code","execution_count":28,"id":"16c17511-01e1-4356-bdbc-8ecfc61594a5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8586,"status":"ok","timestamp":1654585597210,"user":{"displayName":"Matt Chapman","userId":"15238629434520334129"},"user_tz":-60},"id":"16c17511-01e1-4356-bdbc-8ecfc61594a5","outputId":"c8225d43-7091-49aa-ed3f-77dea8ab009a"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/1 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:09<00:00,  9.28s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy after 1 epoch(s): 0.5932203389830508\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:06<00:00,  6.77s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy after 2 epoch(s): 0.5423728813559322\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:09<00:00,  9.59s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy after 3 epoch(s): 0.5932203389830508\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:09<00:00,  9.40s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Accuracy after 4 epoch(s): 0.576271186440678\n","CPU times: user 3min 40s, sys: 11 s, total: 3min 51s\n","Wall time: 1min 1s\n"]}],"source":["%%time\n","\n","# Train model\n","for epoch_i in range(1, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    # Put model into training mode. This is necessary so that the `Dropout`\n","    # layers are activated.\n","    model.train()\n","\n","    # For each batch of the training data...\n","    for i, batch in enumerate(tqdm(train_loader)):\n","\n","        # Step 1. Since PyTorch accumulates gradients, clear any previously\n","        # calculated gradients before performing a backward pass.\n","        # PyTorch doesn't do this automatically because it can be useful while\n","        # training RNNs.\n","        optimizer.zero_grad()\n","\n","        # Step 2. Extract data and move to device.\n","        tweets, masks, labels = [t.to(device) for t in batch]\n","\n","        # Step 3. Forward pass - note that calling `model()` will in turn call\n","        # the model's `forward()` function.\n","        output = model(tweets, masks)\n","\n","        # Step 4. Compute loss.\n","        loss = criterion(output, labels)\n","\n","        # Step 5. Perform backward pass to calculate gradients wrt each w and b term.\n","        loss.backward()\n","\n","        # Step 6. Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Step 7. Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","    # Put model into evaluation mode, thereby deactivating Dropout layer.\n","    model.eval()\n","\n","    y_true = list()\n","    y_pred = list()\n","\n","    with torch.no_grad(): # We no longer need it to store computation graph.\n","        for batch in dev_loader:\n","            tweets, masks, labels = [t.to(device) for t in batch]\n","            output = model(tweets, masks)\n","            max_output = output.argmax(dim=1)\n","            y_true.extend(labels.tolist())\n","            y_pred.extend(max_output.tolist())\n","\n","    print(f\"Accuracy after {epoch_i} epoch(s): {accuracy_score(y_true, y_pred)}\")"]},{"cell_type":"code","execution_count":29,"id":"402beb9a-c8d5-4f89-a06f-59850751da81","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"elapsed":2555,"status":"ok","timestamp":1654585827774,"user":{"displayName":"Matt Chapman","userId":"15238629434520334129"},"user_tz":-60},"id":"402beb9a-c8d5-4f89-a06f-59850751da81","outputId":"4c8a71f8-29f9-404d-8e4f-94a75de57573"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.56\n","\n","Classification report: \n","               precision    recall  f1-score   support\n","\n","           0       0.96      0.54      0.69       541\n","           1       0.16      0.80      0.26        59\n","\n","    accuracy                           0.56       600\n","   macro avg       0.56      0.67      0.48       600\n","weighted avg       0.88      0.56      0.65       600\n","\n","\n","Confusion matrix: \n","\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Predicted: Unhateful</th>\n","      <th>Predicted: Hateful</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Actual: Unhateful</th>\n","      <td>290</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>Actual: Hateful</th>\n","      <td>12</td>\n","      <td>47</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   Predicted: Unhateful  Predicted: Hateful\n","Actual: Unhateful                   290                 251\n","Actual: Hateful                      12                  47"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["CPU times: user 3min 52s, sys: 16.5 s, total: 4min 8s\n","Wall time: 1min 3s\n"]}],"source":["%%time\n","\n","# ========================================\n","#               Evaluation\n","# ========================================\n","\n","# Evaluate model on test data\n","model.eval()\n","\n","y_true = list()\n","y_pred = list()\n","\n","with torch.no_grad():\n","    for batch in test_loader:\n","        tweets, masks, labels = [t.to(device) for t in batch]\n","        output = model(tweets, masks)\n","        max_output = output.argmax(dim=1)\n","        y_true.extend(labels.tolist())\n","        y_pred.extend(max_output.tolist())\n","\n","print('Test accuracy: {:.2f}'.format(accuracy_score(y_true, y_pred)))\n","print('\\nClassification report: \\n', classification_report(y_true, y_pred))\n","print('\\nConfusion matrix: \\n')\n","display(pd.DataFrame({\"Predicted: Unhateful\": confusion_matrix(y_true, y_pred)[:, 0],\n","              \"Predicted: Hateful\": confusion_matrix(y_true, y_pred)[:, 1]},\n","             index=['Actual: Unhateful', 'Actual: Hateful']))"]},{"cell_type":"markdown","id":"b686f4a4-e904-4783-ae21-8cac3474204a","metadata":{"id":"b686f4a4-e904-4783-ae21-8cac3474204a"},"source":["## Comparison to baselines"]},{"cell_type":"markdown","id":"f86d0ccc-b242-46b4-8a94-1847ad039b62","metadata":{"id":"f86d0ccc-b242-46b4-8a94-1847ad039b62"},"source":["### Basic baselines"]},{"cell_type":"code","execution_count":30,"id":"5497a5f6-e58d-4570-9e01-1d8af287eb18","metadata":{"id":"5497a5f6-e58d-4570-9e01-1d8af287eb18","outputId":"a052469a-1d24-4ca7-8af3-83b4ad081f14","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.90      1.00      0.95       541\n","           1       0.00      0.00      0.00        59\n","\n","    accuracy                           0.90       600\n","   macro avg       0.45      0.50      0.47       600\n","weighted avg       0.81      0.90      0.86       600\n","\n"]},{"name":"stderr","output_type":"stream","text":["/home/niki/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/niki/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/home/niki/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# Predict all majority class\n","y_pred = [0] * len(test)\n","y_true = test['HOF']\n","print(classification_report(y_true, y_pred))"]},{"cell_type":"code","execution_count":31,"id":"3135979f-ed60-427a-b3a4-079959dd6693","metadata":{"id":"3135979f-ed60-427a-b3a4-079959dd6693","outputId":"0a8aa4e4-0728-495e-e358-31a995ddf788"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.90      0.90      0.90       541\n","           1       0.10      0.10      0.10        59\n","\n","    accuracy                           0.82       600\n","   macro avg       0.50      0.50      0.50       600\n","weighted avg       0.82      0.82      0.82       600\n","\n"]}],"source":["# Probabilistic guess\n","maj_prob, min_prob = test['HOF'].value_counts(normalize=True).values\n","y_pred = [0]*int(maj_prob*len(test)) + [1]*int(min_prob*len(test))\n","y_pred = random.sample(y_pred, len(y_pred))\n","print(classification_report(y_true, y_pred))"]},{"cell_type":"markdown","id":"0f651303-13b8-4e86-8d9f-3d3fe7076074","metadata":{"id":"0f651303-13b8-4e86-8d9f-3d3fe7076074"},"source":["### Naïve Bayes BoW classifier"]},{"cell_type":"code","execution_count":32,"id":"4b35defb-dc43-4519-bdb2-19e18076b985","metadata":{"id":"4b35defb-dc43-4519-bdb2-19e18076b985"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'naive_bayes'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'naive_bayes'"]}],"source":["from naive_bayes import *"]},{"cell_type":"code","execution_count":null,"id":"6240470a-1d5f-413e-a3f4-3da53ab51f5e","metadata":{"id":"6240470a-1d5f-413e-a3f4-3da53ab51f5e","outputId":"54786640-be51-4866-9f73-7f402ac2b18e"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.91      0.69      0.78       541\n","           1       0.11      0.34      0.16        59\n","\n","    accuracy                           0.65       600\n","   macro avg       0.51      0.51      0.47       600\n","weighted avg       0.83      0.65      0.72       600\n","\n"]}],"source":["# Generate vocabs\n","n_total, vocab, distinct_mentions = get_vocabs(train)\n","\n","# Generate MI list\n","mi_list = sorted([(mi(w, distinct_mentions, n_total), w) for w in set(vocab[1]).union(set(vocab[0]))], reverse=True)\n","\n","# Estimate P(c_i), the probability of class c_i\n","categories = [0, 1]\n","prob_class = dict()\n","total_tweets = len(train)\n","for c_i in categories:\n","    prob_class[c_i] = len(train[train['HOF']==c_i]) / total_tweets\n","\n","# Get predictions on test set using arbitrary values for n_features and smoothing_alpha\n","# This is just to test that it works\n","probs = naive_bayes_additive_smoothing_feature_selection(vocab, categories, 0.25, 1000, mi_list)\n","labels, predictions = get_nb_predictions(categories, test, probs, prob_class)\n","print(classification_report(labels, predictions))"]},{"cell_type":"markdown","id":"8992b65d-6c54-4e79-bc16-b2503cfe38ab","metadata":{"id":"8992b65d-6c54-4e79-bc16-b2503cfe38ab","tags":[]},"source":["## Future improvements\n","\n","1. Better ways of dealing with class imbalances - e.g. upsampling, to avoid wasting data.\n","\n","2. Modify loss function to penalize False Positives and False Negatives with different magnitudes. E.g. if simple Cross Entropy looks like this:\n","\n","$$\\frac{-1}{N} \\sum_{i=1}^Ny_i \\cdot \\log(\\hat{y_i}) + (1 - y_i) \\cdot \\log(1 - \\hat{y_i})$$\n","\n","Where:\n","* $y_i \\cdot \\log(\\hat{y_i})$ penalises False Negatives\n","* $(1 - y_i) \\cdot \\log(1 - \\hat{y_i})$ penalises False Positives\n","\n","We could introduce some new scalar parameters to change the size/influence of these.\n","\n","3. Incorporate contextual information - original authors Grimminger and Klinger (2021) found that knowing whether or not a user was a supporter of a particular candidate massively boosted the F1 score.\n","\n","4. Interpretability - e.g. using LIME.\n","\n","5. Could try different levels of cleaning. BERT obviously needs contextual information, so I would only do limited cleaning, but could explore whether, for example, including some form of tagged users' names helps the model improve.\n","\n","6. Hyperparameter tuning\n","\n","7. I might consider making use of additional 🤗 Transformers tools like the `Trainer` object for more streamlined/customisable pipeline:\n","\n","```python\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=small_train_dataset,\n","    eval_dataset=small_eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","```"]},{"cell_type":"code","execution_count":null,"id":"933794ec-8fb1-4e95-97d1-d28994d5dad1","metadata":{"id":"933794ec-8fb1-4e95-97d1-d28994d5dad1"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1d_q0vUpgwmbN7imUcdsbuDwJ61OuBjvO","timestamp":1705225836644}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":5}
